{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "",
  "signature": "sha256:dd0307c3eac3b23205ee21fec096330706d40e72c3592e30e73ca3446181ebf6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Final Project - CS 281"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ankit Gupta"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import Statements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import stats as scistats\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.mlab as mlab\n",
      "from IPython.display import Image\n",
      "import lda\n",
      "from scipy.sparse import csr_matrix\n",
      "\n",
      "%matplotlib inline\n",
      "from CTM import CTM\n",
      "from CTMParallel import CTMParallel\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Returns the min, max, and average accuracy across the folds\n",
      "def KFoldCrossValidation(X, Y, num_folds, print_outputs=True):\n",
      "    accuracies = []\n",
      "    for train, test in KFold(X.shape[0], num_folds, shuffle=True):\n",
      "        X_train, X_test, Y_train, Y_test = X[train], X[test], Y[train], Y[test]\n",
      "        logistic_classifier = LogisticRegression()\n",
      "        logistic_classifier.fit(X_train, Y_train)\n",
      "        accuracies.append(accuracy_score(logistic_classifier.predict(X_test), Y_test))\n",
      "    if print_outputs:\n",
      "        print \"Max Accuracy: \", max(accuracies), \"\\nMin Accuracy: \", min(accuracies), \"\\nAverage Accuracy: \", sum(accuracies)/len(accuracies)\n",
      "    return max(accuracies), min(accuracies), sum(accuracies)/len(accuracies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove genes that are super high in expression.\n",
      "#features =  pd.read_table(\"GSE60361_C1-3005-Expression.txt\", sep='\\t', usecols=range(3006)).set_index('cell_id').T\n",
      "#genes_of_interest = (-features.sum()).sort(inplace=False)[20:].index\n",
      "#remove_low_expression_genes = features.sum() > 100\n",
      "#genes_wanted = remove_low_expression_genes[remove_low_expression_genes].index.intersection(genes_of_interest)\n",
      "#genes_of_interest = genes_of_interest & remove_low_expression_genes\n",
      "#features = features.ix[:, genes_wanted]\n",
      "\n",
      "#vocab = features.columns\n",
      "#compressed_features = csr_matrix(features)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#features.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(3005, 12883)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compressed_features.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(3005, 12883)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#len(set(map(lambda x: x.split('_')[0], features.index.tolist())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "76"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import csv\n",
      "#lines = []\n",
      "#with open(\"expression_mRNA_17-Aug-2014.txt\", 'r') as f:\n",
      "#    reader = csv.reader(f, delimiter='\\t')\n",
      "#    for line in reader:\n",
      "#        lines.append(line)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#metadata = pd.DataFrame(lines)\n",
      "#metadata = metadata.set_index(0)\n",
      "#metadata.columns = metadata.ix['cell_id', :]\n",
      "#metadata.columns = metadata.ix[7, :]\n",
      "#metadata.rename(columns={'cell_id':'info'}).set_index('info')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#metadata =  pd.read_table(\"expression_mRNA_17-Aug-2014.txt\", sep='\\t', nrows=15, header=0, usecols=range(3006)).rename(columns={'tissue':'info'}).set_index('info')\n",
      "#data =  pd.read_csv(\"expression_mRNA_17-Aug-2014.txt\", sep='\\t', skiprows=range(1, 11), usecols=range(3006), header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#classification = metadata.ix['group #', :]\n",
      "\n",
      "# This contains the classification for each gene into 9 major classes of genes.\n",
      "# We can compare the classification problem using standard SVM to that with LDA, and later with Pachinko Allocation.\n",
      "#classification = classification[features.index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#classification.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(3005,)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X_train, X_test, y_train, y_test = train_test_split(features, classification, train_size=500, test_size=100, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#X_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compressed_features.todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "matrix([[ 3,  1,  1, ...,  0,  0,  0],\n",
        "        [43, 17, 59, ...,  0,  0,  0],\n",
        "        [30, 11, 80, ...,  0,  0,  0],\n",
        "        ..., \n",
        "        [ 5,  5,  0, ...,  0,  0,  0],\n",
        "        [ 6,  4,  4, ...,  0,  0,  0],\n",
        "        [ 4, 24,  0, ...,  0,  0,  0]])"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model = lda.LDA(n_topics=10, n_iter=20)\n",
      "#model.fit(compressed_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "<lda.lda.LDA instance at 0x10b592a70>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#model30 = lda.LDA(n_topics=30, n_iter=20)\n",
      "#model30.fit(compressed_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<lda.lda.LDA instance at 0x10b594fc8>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#n_top_words = 8\n",
      "#for i, topic_dist in enumerate(model.topic_word_):\n",
      "#    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
      "#    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic 0: Stmn3 Snca Aldoa Tubb2a Chn1 Scg5 Mdh1\n",
        "Topic 1: Dynll1 Usmg5 Slc25a4 Mdh1 Ndufa4 Scg5 Eif4a2\n",
        "Topic 2: Rtn1 Syt1 Nrgn Olfm1 Cpe Basp1 Camk2n1\n",
        "Topic 3: Mdh1 Usmg5 Ndufa4 Rps29 Cox7c Cox7a2 Cycs\n",
        "Topic 4: Cst3 Sparcl1 Apoe Slc1a2 Atp1a2 Mt1 Clu\n",
        "Topic 5: Apod Mbp Ttr Mog Enpp2 Car2 Ptgds\n",
        "Topic 6: Rps29 Hbb-bs Sparc Itm2a Hba-a2_loc2 Hba-a2_loc1 Rplp1\n",
        "Topic 7: Ppp3ca Snhg11 Prkcb D3Bwg0562e Prnp Gria1 Cpe\n",
        "Topic 8: Sst Npy Syt1 Cnr1 Vip Htr3a Gad1\n",
        "Topic 9: Aldoa Rtn1 Hspa8 Actg1 Chn1 Cpe Ywhaz\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This gives you a distribution over words (genes) for each topic. Each row sums to 1.\n",
      "#model.topic_word_\n",
      "\n",
      "# These gives you a distribution over topics for each doc (sample)\n",
      "#     This can serve as a dimensionality reduction!\n",
      "#model.doc_topic_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[  2.17097254e-03,   6.76315434e-06,   1.27627485e-01, ...,\n",
        "          9.97632896e-02,   2.90883268e-02,   8.59596916e-03],\n",
        "       [  2.94480077e-02,   1.44487652e-02,   1.37472855e-01, ...,\n",
        "          2.72764002e-02,   6.77294076e-01,   5.74263926e-02],\n",
        "       [  4.78744179e-02,   2.53918181e-02,   1.33298283e-01, ...,\n",
        "          1.25231586e-02,   6.50898803e-01,   5.14796455e-02],\n",
        "       ..., \n",
        "       [  4.25170068e-05,   4.25170068e-05,   1.40731293e-02, ...,\n",
        "          4.25170068e-05,   1.40731293e-02,   4.25170068e-05],\n",
        "       [  2.01419698e-02,   2.78320024e-02,   1.18041999e-01, ...,\n",
        "          2.46406389e-01,   1.89588879e-02,   7.21975747e-02],\n",
        "       [  1.48697395e-02,   3.64729459e-03,   4.00801603e-05, ...,\n",
        "          1.24248497e-03,   4.00801603e-05,   4.44889780e-03]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#document_distribution = pd.DataFrame(model.doc_topic_, index=features.index)\n",
      "#corresponding_classifications = classification[document_distribution.index]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn.cross_validation import train_test_split\n",
      "#from sklearn.svm import SVC\n",
      "#from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get a test set from 10 percent of the data.\n",
      "#doc_train, doc_test, class_train, class_test = train_test_split(document_distribution, corresponding_classifications, test_size=.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#clf = SVC()\n",
      "#clf.fit(doc_train, class_train)\n",
      "#accuracy = accuracy_score(clf.predict(doc_test), class_test)\n",
      "#print accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.784053156146\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#feat_classification = classification[features.index]\n",
      "#feat_train, feat_test, feat_class_train, feat_class_test = train_test_split(features, feat_classification, test_size=.1)\n",
      "\n",
      "#clf_original = SVC()\n",
      "#clf_original.fit(doc_train, class_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#clf_orig_features = SVC()\n",
      "#clf_orig_features.fit(feat_train, feat_class_train)\n",
      "#accuracy_orig_features = accuracy_score(clf_orig_features.predict(feat_test), feat_class_test)\n",
      "#print accuracy_orig_features\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.707641196013\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#try the same thing after using PCA for dimensionality reduction.\n",
      "#from sklearn.decomposition import PCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pca = PCA(n_components=20)\n",
      "#pca_features= pca.fit_transform(features)\n",
      "#pca_classification = classification[features.index]\n",
      "#pca_train, pca_test, pca_class_train, pca_class_test = train_test_split(pca_features, pca_classification, test_size=.1)\n",
      "#clf_pca_features = SVC()\n",
      "#clf_pca_features.fit(pca_train, pca_class_train)\n",
      "#accuracy_pca_features = accuracy_score(clf_pca_features.predict(pca_test), pca_class_test)\n",
      "#print accuracy_pca_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.308970099668\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do all of the above using LogisticRegression\n",
      "#from sklearn.linear_model import LogisticRegression\n",
      "#import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#logistic_orig_features = LogisticRegression()\n",
      "#logistic_pca_features = LogisticRegression()\n",
      "#logistic_lda_features = LogisticRegression()\n",
      "\n",
      "#logistic_orig_features.fit(feat_train, feat_class_train)\n",
      "#logistic_pca_features.fit(pca_train, pca_class_train)\n",
      "#logistic_lda_features.fit(doc_train, class_train)\n",
      "\n",
      "#logistic_orig_accuracy = accuracy_score(logistic_orig_features.predict(feat_test), feat_class_test)\n",
      "#logistic_pca_accuracy = accuracy_score(logistic_pca_features.predict(pca_test), pca_class_test)\n",
      "#logistic_lda_accuracy = accuracy_score(logistic_lda_features.predict(doc_test), class_test)\n",
      "\n",
      "#print \"Original Features Score\", logistic_orig_accuracy\n",
      "#sys.stdout.flush()\n",
      "#print \"PCA Features Score\", logistic_pca_accuracy\n",
      "#sys.stdout.flush()\n",
      "#print \"LDA Features Score\", logistic_lda_accuracy\n",
      "#sys.stdout.flush()\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original Features Score 0.963455149502\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PCA Features Score 0.953488372093\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LDA Features Score 0.830564784053\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#compressed_features.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "(3005, 12883)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#numTopicsWanted = 4\n",
      "#ctm = CTMParallel(compressed_features.shape[0], numTopicsWanted, compressed_features.shape[1],compressed_features.todense(), 10, .001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ctm.EM()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x1 = np.ones((19956, 4))\n",
      "#x2 = np.linspace(0, 19956, 19956 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "(19956, 4)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x2[:, np.newaxis].T.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(1, 19956)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#np.multiply(x1,x2[:, np.newaxis])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
        "          0.00000000e+00],\n",
        "       [  1.00005011e+00,   1.00005011e+00,   1.00005011e+00,\n",
        "          1.00005011e+00],\n",
        "       [  2.00010023e+00,   2.00010023e+00,   2.00010023e+00,\n",
        "          2.00010023e+00],\n",
        "       ..., \n",
        "       [  1.99539999e+04,   1.99539999e+04,   1.99539999e+04,\n",
        "          1.99539999e+04],\n",
        "       [  1.99549999e+04,   1.99549999e+04,   1.99549999e+04,\n",
        "          1.99549999e+04],\n",
        "       [  1.99560000e+04,   1.99560000e+04,   1.99560000e+04,\n",
        "          1.99560000e+04]])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "This part performs LDA on the Rat and Neuron Data, and saves the resultant models to pickle objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import stats as scistats\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.mlab as mlab\n",
      "from IPython.display import Image\n",
      "import lda\n",
      "from scipy.sparse import csr_matrix\n",
      "\n",
      "%matplotlib inline\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from CTM import CTM\n",
      "#from CTMParallel import CTMParallel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('counts_rat.csv').set_index('GeneID')\n",
      "genes_wanted = (data > 1).sum(axis=1) > 5\n",
      "genes_wanted = data.var(axis=1).divide(data.mean(axis=1)).sort(inplace=False, ascending=False)[:1000].index\n",
      "counts_newsetup = data.ix[genes_wanted, :].T\n",
      "classes = np.array(map(lambda x: x.split(\"_\")[0], counts_newsetup.index))\n",
      "vocab = counts_newsetup.columns\n",
      "counts = counts_newsetup.values\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_options = [15, 25, 35, 45]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topics in topic_options:\n",
      "    print \"Working on topic\", topics\n",
      "    sys.stdout.flush()\n",
      "    model = lda.LDA(n_topics=topics, n_iter=10)\n",
      "    model.fit(counts)\n",
      "    print \"    Saving pickled model\"\n",
      "    sys.stdout.flush()\n",
      "    pickle.dump(vocab, open(\"pickled_objects/lda_vocab_rat_\" + str(topics) + \"topics.p\", \"wb\"))\n",
      "    pickle.dump(counts, open(\"pickled_objects/lda_counts_rat_\" + str(topics) + \"topics.p\", \"wb\"))\n",
      "    pickle.dump(classes, open(\"pickled_objects/lda_classes_rat_\" + str(topics) + \"topics.p\", \"wb\"))\n",
      "    pickle.dump(model, open(\"pickled_objects/lda_model_rat_\" + str(topics) + \"topics.p\", \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Working on topic 15\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    Saving pickled model\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Working on topic 25\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features =  pd.read_table(\"GSE60361_C1-3005-Expression.txt\", sep='\\t', usecols=range(3006)).set_index('cell_id').T\n",
      "lines = []\n",
      "with open(\"expression_mRNA_17-Aug-2014.txt\", 'r') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    for line in reader:\n",
      "        lines.append(line)\n",
      "metadata = pd.DataFrame(lines)\n",
      "metadata = metadata.set_index(0)\n",
      "metadata.columns = metadata.ix['cell_id', :]\n",
      "classification = metadata.ix['group #', :]\n",
      "\n",
      "# This contains the classification for each gene into 9 major classes of genes.\n",
      "\n",
      "genes_of_interest = (-features.sum()).sort(inplace=False)[20:].index\n",
      "remove_low_expression_genes = features.sum() > 100\n",
      "genes_wanted = remove_low_expression_genes[remove_low_expression_genes].index.intersection(genes_of_interest)\n",
      "genes_wanted = features.T.var(axis=1).sort(inplace=False, ascending=False)[:1000].index.intersection(genes_wanted)\n",
      "print \"Number of genes being investigated\", len(genes_wanted)\n",
      "features = features.ix[:, genes_wanted]\n",
      "classification = classification[features.index]\n",
      "vocab = features.columns\n",
      "X_train, X_test, y_train, y_test, samples_train, samples_test = train_test_split(features, classification, features.index, train_size=500, test_size=100, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neuron_topic_options = [5, 15, 25, 35, 45, 55]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topics in neuron_topic_options:\n",
      "    print \"Working on topic\", topics\n",
      "    sys.stdout.flush()\n",
      "    model = lda.LDA(n_topics=topics, n_iter=10)\n",
      "    model.fit(X_train)\n",
      "    print \"    Saving pickled model\"\n",
      "    sys.stdout.flush()\n",
      "    pickle.dump(vocab, open(\"pickled_objects/lda_vocab_neuron_\" + str(topics) + \"topics.p\", \"wb\"))\n",
      "    pickle.dump(X_train, open(\"pickled_objects/lda_counts_neuron_\" + str(topics) + \"topics.p\", \"wb\"))\n",
      "    pickle.dump(y_train, open(\"pickled_objects/lda_classes_neuron_\" + str(topics) + \"topics.p\", \"wb\"))\n",
      "    pickle.dump(model, open(\"pickled_objects/lda_model_neuron_\" + str(topics) + \"topics.p\", \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#KFoldCrossValidation(model.doc_topic_, classes, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}