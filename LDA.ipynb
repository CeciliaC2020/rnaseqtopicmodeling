{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "",
  "signature": "sha256:7c0e3af7f071fbe0b3c8d388acd8e350736e8ba057ffd30b6d594b599307addf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Final Project - CS 281"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ankit Gupta"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import Statements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import stats as scistats\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.mlab as mlab\n",
      "from IPython.display import Image\n",
      "import lda\n",
      "from scipy.sparse import csr_matrix\n",
      "\n",
      "%matplotlib inline\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove genes that are super high in expression.\n",
      "features =  pd.read_table(\"GSE60361_C1-3005-Expression.txt\", sep='\\t', usecols=range(3006)).set_index('cell_id').T\n",
      "genes_of_interest = (-features.sum()).sort(inplace=False)[20:].index\n",
      "features = features.ix[:, genes_of_interest]\n",
      "vocab = features.columns\n",
      "compressed_features = csr_matrix(features)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(map(lambda x: x.split('_')[0], features.index.tolist())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "76"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "lines = []\n",
      "with open(\"expression_mRNA_17-Aug-2014.txt\", 'r') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    for line in reader:\n",
      "        lines.append(line)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata = pd.DataFrame(lines)\n",
      "metadata = metadata.set_index(0)\n",
      "metadata.columns = metadata.ix['cell_id', :]\n",
      "#metadata.columns = metadata.ix[7, :]\n",
      "#metadata.rename(columns={'cell_id':'info'}).set_index('info')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#metadata =  pd.read_table(\"expression_mRNA_17-Aug-2014.txt\", sep='\\t', nrows=15, header=0, usecols=range(3006)).rename(columns={'tissue':'info'}).set_index('info')\n",
      "#data =  pd.read_csv(\"expression_mRNA_17-Aug-2014.txt\", sep='\\t', skiprows=range(1, 11), usecols=range(3006), header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classification = metadata.ix['group #', :]\n",
      "\n",
      "# This contains the classification for each gene into 9 major classes of genes.\n",
      "# We can compare the classification problem using standard SVM to that with LDA, and later with Pachinko Allocation.\n",
      "classification.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "cell_id\n",
        "1772071015_C02    1\n",
        "1772071017_G12    1\n",
        "1772071017_A05    1\n",
        "1772071014_B06    1\n",
        "1772067065_H06    1\n",
        "Name: group #, dtype: object"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = lda.LDA(n_topics=50, n_iter=20)\n",
      "model.fit(compressed_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<lda.lda.LDA instance at 0x10a7c6e60>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_top_words = 8\n",
      "for i, topic_dist in enumerate(model.topic_word_):\n",
      "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
      "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic 0: Snhg11 Syt1 Map1b Olfm1 Rtn1 Ttc3 Kif1b\n",
        "Topic 1: Nrgn Rtn1 Syt1 Camk2b Basp1 Aplp1 Prkcb\n",
        "Topic 2: Cpe Prkcb Aplp1 Actg1 Chn1 Ttc3 Sub1\n",
        "Topic 3: Mef2c Camk2n1 Lars2 Syt1 Slc1a2 Atp2b2 2900097C17Rik\n",
        "Topic 4: Ttr Dbi Enpp2 Mt1 Rps29 Clu Cd9\n",
        "Topic 5: Rps29 Cox7c Actg1 Rplp1 Sub1 Lars2 Cox6b1\n",
        "Topic 6: Apod Qk Aplp1 Fos Kif1b Scd2 Sepp1\n",
        "Topic 7: Aldoa Hspa8 Rtn1 Atp6v0c-ps2 Actg1 Slc25a4 Atp6v1a\n",
        "Topic 8: Stmn3 Dynll1 Snca Chn1 Fkbp1a Tubb2a 3110035E14Rik\n",
        "Topic 9: Cox7c Rps29 Slc25a4 Ckb Cox6c Dynll1 Atp5c1\n",
        "Topic 10: Mdh1 Stmn2 Tpi1 Ndufa4 Eif4a2 Stmn3 Snca\n",
        "Topic 11: Gstp1 Taldo1 Prdx1 H3f3b Fau Srp14 Ptn\n",
        "Topic 12: Hpca Chn1 Itm2b Actg1 Ppp3ca Cpe Ywhaz\n",
        "Topic 13: Cox6b1 Mdh1 Cox8a Slc25a4 Cox7a2 Cox7c Cox6c\n",
        "Topic 14: D3Bwg0562e Gria1 Ppp3ca Tcf4 Camk2b Wfs1 Trim2\n",
        "Topic 15: Cst3 Rps29 Cox7c Ckb Cox4i1 Cox6b1 Slc25a4\n",
        "Topic 16: Dcn Itm2b Dynll1 Sub1 Slc25a4 Rps29 Actg1\n",
        "Topic 17: Dynll1 Scg5 Usmg5 Cox7c Cox8a Pcsk2 Chn1\n",
        "Topic 18: Mdh1 Tpi1 Tubb2a Eif4a2 Zwint Stmn2 Usmg5\n",
        "Topic 19: Hpca Ppp3ca Neurod6 Crym Prnp Prkcb Tspan13\n",
        "Topic 20: Aldoa Stmn3 Snca Nsf Hspa8 Gap43 Stmn2\n",
        "Topic 21: Pcp4 Mdh1 Tagln3 Pcsk2 Ndufa4 Ncald Aldoa\n",
        "Topic 22: Xist Jun Fos Eef1a1 Qk Ptma Ubc\n",
        "Topic 23: Ptgds Car2 Apod Gstp1 Cryab Fabp5 Dbi\n",
        "Topic 24: Usmg5 Scg5 Cox7c Rps29 Mdh1 Cox6c Rplp1\n",
        "Topic 25: Cst3 Apoe Rps29 Ftl1 Sepp1 Ccl7 Lyz2\n",
        "Topic 26: Chn1 Dynll1 Stmn3 3110035E14Rik Snca Slc25a4 Pde1a\n",
        "Topic 27: Rps29 H3f3b Cox8a Cox7c Cox6c Tecr Syt11\n",
        "Topic 28: Cnp Mog Mbp Mobp Scd2 Ugt8a Tspan2\n",
        "Topic 29: Hbb-bs Itm2a Sparc Hba-a2_loc2 Hba-a2_loc1 Ly6c1 Bsg\n",
        "Topic 30: Rps29 Rplp1 Rplp2 Dynll1 Sub1 Fau Rps28\n",
        "Topic 31: Ppp3ca Cpe Prkcb Slc8a1 Tspan13 Rtn1 Prnp\n",
        "Topic 32: Nrgn Basp1 Syt1 2900097C17Rik Prkcb Rtn1 3110035E14Rik"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Topic 33: Nrgn Ppp3ca Npcd Snhg11 Prkcb Olfm1 Rtn1\n",
        "Topic 34: Chn1 Pcsk2 Scg5 Usmg5 Ntm Prkcb Cox8a\n",
        "Topic 35: Itm2b Aldoa Xist Cox8a Sub1 Actg1 Amd2\n",
        "Topic 36: Snhg11 Prkcb Kcnq1ot1 Camk2a Ppp3ca Kif1b Ttc3\n",
        "Topic 37: Syt1 Camk2n1 Ndrg4 Rtn1 Map1b Ttc3 2900097C17Rik\n",
        "Topic 38: Camk2n1 Nrgn Rgs4 Arpp21 Olfm1 Chn1 Mef2c\n",
        "Topic 39: Sst Npy Mdh1 Scg5 Ndufa4 Stmn3 Zwint\n",
        "Topic 40: Aldoa Atp6v0c-ps2 Cpe Celf4 2900097C17Rik Atp6v1a Ywhaz\n",
        "Topic 41: Itm2b Ywhaz Snhg11 Calm3 Rtn1 Actg1 Pja2\n",
        "Topic 42: Tubb2a Cpe Aldoa Sub1 Chn1 Rtn1 Actg1\n",
        "Topic 43: Snhg11 Nnat Rtn1 Ttc3 Cpe Prnp Syt1\n",
        "Topic 44: Mdh1 Cox7a2 Ndufa4 Scg5 Atpif1 Usmg5 Cox4i1\n",
        "Topic 45: Mbp Nfasc Mag Cd81 Sirt2 Cnp Ctsl\n",
        "Topic 46: Cst3 Sparcl1 Slc1a2 Atp1a2 Apoe Mt1 Cpe\n",
        "Topic 47: Cnr1 Vip Htr3a Syt1 Gad1 Gad2 Nap1l5\n",
        "Topic 48: Acta2 Sparcl1 Myl6 Crip1 Myl9 Tagln Tpm1\n",
        "Topic 49: Apod Enpp2 Mog Ermn Mbp Ugt8a Car2\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This gives you a distribution over words (genes) for each topic. Each row sums to 1.\n",
      "model.topic_word_\n",
      "\n",
      "# These gives you a distribution over topics for each doc (sample)\n",
      "#     This can serve as a dimensionality reduction!\n",
      "model.doc_topic_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([[  2.41509219e-02,   5.82795822e-03,   5.70808836e-06, ...,\n",
        "          1.51892231e-02,   6.74753125e-02,   1.35909584e-02],\n",
        "       [  8.67887508e-02,   1.57518740e-02,   2.47019168e-03, ...,\n",
        "          4.79956734e-01,   1.91678825e-03,   3.22483272e-03],\n",
        "       [  5.99940111e-02,   2.25632580e-02,   7.94031043e-03, ...,\n",
        "          4.38094525e-01,   9.58726356e-03,   2.04621450e-04],\n",
        "       ..., \n",
        "       [  8.83954755e-03,   4.18935903e-05,   4.18935903e-05, ...,\n",
        "          4.60829493e-04,   3.18852116e-01,   4.18935903e-05],\n",
        "       [  3.53370295e-02,   1.14093960e-02,   3.53078494e-03, ...,\n",
        "          2.91800409e-05,   2.42223519e-01,   2.91800409e-05],\n",
        "       [  3.95882819e-05,   3.60253365e-03,   3.95882819e-05, ...,\n",
        "          3.95882819e-05,   3.29809976e-01,   3.95882819e-05]])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "document_distribution = pd.DataFrame(model.doc_topic_, index=features.index)\n",
      "corresponding_classifications = classification[document_distribution.index]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.metrics import accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get a test set from 10 percent of the data.\n",
      "doc_train, doc_test, class_train, class_test = train_test_split(document_distribution, corresponding_classifications, test_size=.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC()\n",
      "clf.fit(doc_train, class_train)\n",
      "accuracy = accuracy_score(clf.predict(doc_test), class_test)\n",
      "print accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.720930232558\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat_classification = classification[features.index]\n",
      "feat_train, feat_test, feat_class_train, feat_class_test = train_test_split(features, feat_classification, test_size=.1)\n",
      "\n",
      "#clf_original = SVC()\n",
      "#clf_original.fit(doc_train, class_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_orig_features = SVC()\n",
      "clf_orig_features.fit(feat_train, feat_class_train)\n",
      "accuracy_orig_features = accuracy_score(clf_orig_features.predict(feat_test), feat_class_test)\n",
      "print accuracy_orig_features\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.757475083056\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#try the same thing after using PCA for dimensionality reduction.\n",
      "from sklearn.decomposition import PCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca = PCA(n_components=20)\n",
      "pca_features= pca.fit_transform(features)\n",
      "pca_classification = classification[features.index]\n",
      "pca_train, pca_test, pca_class_train, pca_class_test = train_test_split(pca_features, pca_classification, test_size=.1)\n",
      "clf_pca_features = SVC()\n",
      "clf_pca_features.fit(pca_train, pca_class_train)\n",
      "accuracy_pca_features = accuracy_score(clf_pca_features.predict(pca_test), pca_class_test)\n",
      "print accuracy_pca_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.259136212625\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do all of the above using LogisticRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logistic_orig_features = LogisticRegression()\n",
      "logistic_pca_features = LogisticRegression()\n",
      "logistic_lda_features = LogisticRegression()\n",
      "\n",
      "logistic_orig_features.fit(feat_train, feat_class_train)\n",
      "logistic_pca_features.fit(pca_train, pca_class_train)\n",
      "logistic_lda_features.fit(doc_train, class_train)\n",
      "\n",
      "logistic_orig_accuracy = accuracy_score(logistic_orig_features.predict(feat_test), feat_class_test)\n",
      "logistic_pca_accuracy = accuracy_score(logistic_pca_features.predict(pca_test), pca_class_test)\n",
      "logistic_lda_accuracy = accuracy_score(logistic_lda_features.predict(doc_test), class_test)\n",
      "\n",
      "print \"Original Features Score\", logistic_orig_accuracy\n",
      "sys.stdout.flush()\n",
      "print \"PCA Features Score\", logistic_pca_accuracy\n",
      "sys.stdout.flush()\n",
      "print \"LDA Features Score\", logistic_lda_accuracy\n",
      "sys.stdout.flush()\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original Features Score 0.946843853821\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PCA Features Score 0.936877076412\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LDA Features Score 0.950166112957\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
        "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}