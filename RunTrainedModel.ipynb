{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode EXPIRED 5 days ago\n",
      "\n",
      "    Your usage of mkl is now out of compliance with the license agreement.\n",
      "    A license for mkl can be purchased at: http://continuum.io\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import CTMParallel\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the min, max, and average accuracy across the folds\n",
    "def KFoldCrossValidation(X, Y, num_folds, print_outputs=True):\n",
    "    accuracies = []\n",
    "    for train, test in KFold(X.shape[0], num_folds, shuffle=True):\n",
    "        X_train, X_test, Y_train, Y_test = X[train], X[test], Y[train], Y[test]\n",
    "        logistic_classifier = LogisticRegression()\n",
    "        logistic_classifier.fit(X_train, Y_train)\n",
    "        accuracies.append(accuracy_score(logistic_classifier.predict(X_test), Y_test))\n",
    "    if print_outputs:\n",
    "        print \"Max Accuracy: \", max(accuracies), \"\\nMin Accuracy: \", min(accuracies), \"\\nAverage Accuracy: \", sum(accuracies)/len(accuracies)\n",
    "    return max(accuracies), min(accuracies), sum(accuracies)/len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"pickled_objects/model2all.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = pickle.load(open(\"pickled_objects/ytrain2.p\", \"rb\")).astype(int)\n",
    "vocab = pickle.load(open(\"pickled_objects/vocab2.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03702926, -0.03913617, -0.00278356,  0.01772189, -0.01369278,\n",
       "       -0.00544263,  0.02782353,  0.00454954, -0.00705286,  0.01849104])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model.saved_lambdas, axis=0)/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = model.saved_lambdas[:400]\n",
    "test = model.saved_lambdas[400:]\n",
    "ytrain = classes[:400]\n",
    "ytest = classes[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 3 3 3 3 3 4 3 3 4 3 3 3 3 4 3 4 4 3 4 3 4 3 3 3 4 3 3 4 3 4 3 4 3 3\n",
      " 4 4 3 3 3 3 4 4 3 3 4 3 3 3 4 3 4 3 3 4 3 4 4 3 3 3 3 3 3 3 3 3 4 3 4 3 4\n",
      " 3 3 3 4 3 3 3 4 3 3 3 3 4 4 3 3 3 4 3 3 3 4 4 3 4 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55000000000000004"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_new = SVC()\n",
    "clf_new.fit(train, ytrain)\n",
    "#accuracy = accuracy_score(clf_new.predict(test), ytest)\n",
    "print clf_new.predict(test)\n",
    "accuracy_score(clf_new.predict(test), ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.83980724e-03,   1.54193511e-03,   2.72812643e-03, ...,\n",
       "          5.87663877e-06,   6.98193337e-07,   1.03825588e-06],\n",
       "       [  1.55751903e-03,   3.45780897e-04,   1.76039664e-04, ...,\n",
       "          2.80629787e-06,   1.37861005e-06,   5.47598621e-07],\n",
       "       [  1.23266718e-03,   2.34966054e-03,   1.07062053e-03, ...,\n",
       "          2.08968662e-07,   4.49007654e-07,   1.80547039e-06],\n",
       "       ..., \n",
       "       [  1.89113328e-03,   2.19160621e-03,   3.38549396e-03, ...,\n",
       "          3.85065800e-06,   2.63806369e-06,   1.90606428e-06],\n",
       "       [  2.61815433e-03,   1.02113262e-03,   1.88087681e-03, ...,\n",
       "          4.20443035e-06,   3.55334237e-06,   6.26208429e-06],\n",
       "       [  2.49772898e-03,   3.42468308e-03,   2.18003876e-03, ...,\n",
       "          4.26086897e-06,   5.71613178e-06,   1.11735142e-06]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: Snhg11 Sub1 Ppp3ca Ddx5 Cpe Slc25a4 Map1b Syt1 Syt11 Serinc1 Rtn1 Itm2b Hspa8 Ndufa4 Snca Ttc3 Kif1b Gstp1 Ywhag\n",
      "Topic 2: Scg5 Nrgn Aldoa Tubb2a Chn1 Stmn3 Itm2b Prnp Rtn1 Ppp3ca Slc25a4 Calm3 Cpe Fkbp1a Snhg11 Tcf4 Mdh1 Cox7c Aplp1\n",
      "Topic 3: Snhg11 Hspa8 Syt11 Scg5 Rtn1 Lars2 Rps29 Mdh1 Slc25a4 Ttc3 Stmn3 Cst3 Dynll1 Cox7c Prnp Atp6v1a Hpca Ndufa4 Mog\n",
      "Topic 4: Cst3 Gstp1 Ndufa4 Serinc1 Syt1 Mdh1 Aplp1 Rtn1 Ddx5 Ttc3 Cpe Atp6v1a Cox8a Itm2b Stmn3 Rps29 Hpca Dynll1 Sst\n",
      "Topic 5: Ttr Aldoa Prkcb Syt1 Rps29 Map1b Atp6v0c-ps2 Actg1 Npy Atp5a1 Snca Ckb Cpe Sparcl1 Gpm6b Sub1 Itm2b Atp5g3 Chn1\n",
      "Topic 6: Ndufa4 Snhg11 Npy Atp6v1a Map1b Actg1 Ywhaz Slc25a4 Ttc3 Cpe Ptgds Tpi1 Syt1 Sub1 Nrgn Scd2 Snurf Cycs Gm5506_loc1\n",
      "Topic 7: Ptgds Rps29 Apod Mbp Cst3 Mdh1 Enpp2 Cd81 Stmn3 Car2 Lars2 Slc25a4 Fkbp1a Rtn1 Tcf4 Syt11 Aldoa Actg1 Ptma\n",
      "Topic 8: Mdh1 Syt1 Snca 2900097C17Rik Lars2 Syt11 Gstp1 Atp6v0c-ps2 Dynll1 Rps29 Ndufa4 Apod Scd2 Chn1 Serinc1 Scg5 Cst3 Calm3 Atp5b\n",
      "Topic 9: Prkcb Ppp3ca Aldoa Gstp1 Rtn1 Ptgds 2900097C17Rik Actg1 Slc25a4 Cox7c Ttc3 Scg5 Atp6v1a Ttr Ywhaz Eif4a2 Stmn3 Cox8a Ndufa4\n",
      "Topic 10: Cst3 Serinc1 Hspa8 2900097C17Rik Itm2b Syt11 Tubb2a Apod Prnp Aldoa Gpm6b Actg1 Ppp3ca Lars2 Mbp Syt1 Calm3 Cox7c Ywhaz\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "for i, topic_dist in enumerate(model.beta):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i+1, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.70421300e-01,   1.72161600e-02,   2.49712578e-03,\n",
       "         -7.84727266e-03,   4.47817979e-03,   9.99664942e-04,\n",
       "         -1.50568785e-02,  -2.51553479e-03,   8.82178073e-04,\n",
       "         -8.30578223e-03],\n",
       "       [  1.72161600e-02,   6.73010341e-01,   2.75443500e-03,\n",
       "         -9.43203810e-03,   4.36411319e-03,   2.21710892e-03,\n",
       "         -1.55654098e-02,  -1.87742585e-03,   1.55915486e-03,\n",
       "         -9.42240774e-03],\n",
       "       [  2.49712578e-03,   2.75443500e-03,   6.54195927e-01,\n",
       "         -8.01985300e-04,   9.38145201e-04,   2.68442707e-05,\n",
       "         -2.75954319e-03,  -2.63659721e-04,  -6.31642978e-04,\n",
       "         -1.00907940e-03],\n",
       "       [ -7.84727266e-03,  -9.43203810e-03,  -8.01985300e-04,\n",
       "          6.58304398e-01,  -1.59756614e-03,  -1.67591357e-03,\n",
       "          6.76596246e-03,   9.23432330e-04,  -1.52662905e-03,\n",
       "          5.00254034e-03],\n",
       "       [  4.47817979e-03,   4.36411319e-03,   9.38145201e-04,\n",
       "         -1.59756614e-03,   6.55571795e-01,   3.81310093e-04,\n",
       "         -4.79687311e-03,  -8.51314625e-04,   7.60684951e-05,\n",
       "         -2.17853186e-03],\n",
       "       [  9.99664942e-04,   2.21710892e-03,   2.68442707e-05,\n",
       "         -1.67591357e-03,   3.81310093e-04,   6.54251697e-01,\n",
       "         -1.36141895e-03,  -7.43936851e-05,   4.64025297e-04,\n",
       "         -1.41246662e-03],\n",
       "       [ -1.50568785e-02,  -1.55654098e-02,  -2.75954319e-03,\n",
       "          6.76596246e-03,  -4.79687311e-03,  -1.36141895e-03,\n",
       "          6.66883738e-01,   1.97691236e-03,  -7.57421916e-04,\n",
       "          7.56965827e-03],\n",
       "       [ -2.51553479e-03,  -1.87742585e-03,  -2.63659721e-04,\n",
       "          9.23432330e-04,  -8.51314625e-04,  -7.43936851e-05,\n",
       "          1.97691236e-03,   6.53343450e-01,  -1.32496885e-04,\n",
       "          1.03563715e-03],\n",
       "       [  8.82178073e-04,   1.55915486e-03,  -6.31642978e-04,\n",
       "         -1.52662905e-03,   7.60684951e-05,   4.64025297e-04,\n",
       "         -7.57421916e-04,  -1.32496885e-04,   6.54004214e-01,\n",
       "         -1.19577239e-03],\n",
       "       [ -8.30578223e-03,  -9.42240774e-03,  -1.00907940e-03,\n",
       "          5.00254034e-03,  -2.17853186e-03,  -1.41246662e-03,\n",
       "          7.56965827e-03,   1.03563715e-03,  -1.19577239e-03,\n",
       "          6.58148394e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rat Dataset, 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.96875, 0.97812500000000002)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model_rat_10topics = pickle.load(open(\"pickled_objects/modelratserial.p\", \"rb\"))\n",
    "classes_rat_10topics = pickle.load(open(\"pickled_objects/classesratserial.p\", \"rb\"))\n",
    "vocab_rat_10topics = pickle.load(open(\"pickled_objects/vocabratserial.p\", \"rb\"))\n",
    "counts_rat_10topics = pickle.load(open(\"pickled_objects/countsratserial.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine classification accuracy on CTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy:  0.984375 \n",
      "Min Accuracy:  0.953125 \n",
      "Average Accuracy:  0.975\n"
     ]
    }
   ],
   "source": [
    "max_acc, min_acc, avg_acc = KFoldCrossValidation(model_rat_10topics.saved_lambdas, classes, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top genes in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: stonee gokla stawflu Spnb2 Col3a1 Mb Eef1a1.1 Atp5a1 Dst Hbb Myh9 Sparc Hba-a2 Ccdc107 Sftpc B2m Ryr2 Gsn Actb\n",
      "Topic 2: Alb Trf Cps1 Apob Ahsg Kng1andKng2 Apoe Rspo3 Rbp4 Rmrp Ttr Gc Cfh Serpinc1 Cyp2e1 Mug1 Itih3 Scd1 Eef1a1.1\n",
      "Topic 3: gokla stonee Eef1a1.1 Eef1a1 Aldob Lyz2 gawkla Rmrp Sepp1 Sftpc Ctsl Eef2 C4aandC4-2 Atp1a1 Pck1 Ubc Ctsb Apoe Aldh6a1\n",
      "Topic 4: Hbb stonee Hba-a2 Rmrp Ccdc107 LOC360504 Eef1a1.1 Eef1a1 MGC72973 Actb gokla Eef2 Amy2 Psap stawflu Ptprc B2m LOC678701 Rpl4\n",
      "Topic 5: gokla stawflu Rmrp stonee Hsd3b1 Ccdc107 Eef1a1.1 Scd1 Eef1a1 Hao2 Plp1 Cyp11a1 Cyp21a1 Umod Spna2 Cyp11b1 Atp5b Dst Syne1\n",
      "Topic 6: Myh6 Atp2a2 Myh7 Atp5b Ryr2 stonee Hbb Actc1 Tnnt2 stawflu gokla Rmrp Myl2 Col3a1 Tnni3 Mybpc3 Myl3 Lpl Atp5a1\n",
      "Topic 7: Myh4 Acta1 Ckm Tpm1 Pkinase.4 snoflu Ttn Tnnt3 Myl1 Myosin_tail_1.1 Actn3 Aldoa Mb Tnni2 Pygm Eno3 fn3.21 I-set.16 I-set.17\n",
      "Topic 8: gokla Hsd3b1 Star stonee Cyp11a1 Col3a1 Atp5b gawkla Aco2 Col1a2 Syne1 Sparc Atp1a2andAtp1a4 Abcc5 nyto Spnb2 Rmrp Dync1h1 Nedd4\n",
      "Topic 9: Alb Trf Apob Ahsg Hp Gc Serpina1 Pzp Apoe Itih4 stonee Fgb Cp Serpina3k Hpx A2m Mug1 Fgg Apoh\n",
      "Topic 10: Rmrp stonee stawflu Eef1a1 Lyz2 Calm1 Spnb2 Ddx5 gokla Ccdc107 Mbp Spna2 Sftpc Plp1 Cltc Col3a1 Flna Odf2 Psap\n"
     ]
    }
   ],
   "source": [
    "# Get the top genes in each topic\n",
    "n_top_words = 20\n",
    "for i, topic_dist in enumerate(model_rat_10topics.beta):\n",
    "    topic_words = np.array(vocab_rat_10topics)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i+1, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95097003, -1.0838962 ,  0.74885781,  1.11017983,  1.07833787,\n",
       "         1.47515872,  0.69552146,  1.06558292, -1.49773156,  1.06654061],\n",
       "       [-1.0838962 ,  3.81782433,  0.51714093, -0.79596376, -0.18995724,\n",
       "        -1.57807808, -2.23056967, -0.96812839,  3.72590127, -0.81540821],\n",
       "       [ 0.74885781,  0.51714093,  2.27218235,  1.03908524,  1.47909758,\n",
       "         0.24971437, -1.57109743,  0.44130517,  0.51706189,  0.96670897],\n",
       "       [ 1.11017983, -0.79596376,  1.03908524,  3.34037111,  1.1510328 ,\n",
       "         0.74777914, -1.20853617,  0.35554637, -1.18931525,  1.4001093 ],\n",
       "       [ 1.07833787, -0.18995724,  1.47909758,  1.1510328 ,  3.22892075,\n",
       "         0.52085326, -1.33017356,  1.43138838, -0.26380363,  1.92259898],\n",
       "       [ 1.47515872, -1.57807808,  0.24971437,  0.74777914,  0.52085326,\n",
       "         2.62771544,  1.77817785,  1.08844762, -2.07627106,  0.74226708],\n",
       "       [ 0.69552146, -2.23056967, -1.57109743, -1.20853617, -1.33017356,\n",
       "         1.77817785,  6.03194407,  0.97027417, -2.85596618, -0.61441469],\n",
       "       [ 1.06558292, -0.96812839,  0.44130517,  0.35554637,  1.43138838,\n",
       "         1.08844762,  0.97027417,  2.24932305, -1.23740046,  1.16332465],\n",
       "       [-1.49773156,  3.72590127,  0.51706189, -1.18931525, -0.26380363,\n",
       "        -2.07627106, -2.85596618, -1.23740046,  5.36357255, -0.89755915],\n",
       "       [ 1.06654061, -0.81540821,  0.96670897,  1.4001093 ,  1.92259898,\n",
       "         0.74226708, -0.61441469,  1.16332465, -0.89755915,  2.76879336]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the covariance matrix between topics\n",
    "model_rat_10topics.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directly use the original counts to train a LogisticRegression classifier\n",
    "# Split into test and training sets for the original counts\n",
    "#train_x, test_x, train_y, test_y = train_test_split(counts, classes, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the classification accuracy on the original gene counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rat_original_counts_logistic = LogisticRegression()\n",
    "#rat_original_counts_logistic.fit(train_x, train_y)\n",
    "#accuracy_score(rat_original_counts_logistic.predict(test_x), test_y)\n",
    "# Directly use the original counts to determine the cross-validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy:  1.0 \n",
      "Min Accuracy:  0.984375 \n",
      "Average Accuracy:  0.996875\n"
     ]
    }
   ],
   "source": [
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(counts, classes, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the classification accuracy on the LDA-based dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To do this using LDA, see the other iPython notebook, LDA.ipynb. From there, I found that the accuracy, using the same method, was .875. In other words, this method beats LDA in terms of dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the classification accuracy by applying PCA to the original counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy:  0.96875 \n",
      "Min Accuracy:  0.875 \n",
      "Average Accuracy:  0.915625\n"
     ]
    }
   ],
   "source": [
    "pca_rat_ctm = PCA(n_components=10)\n",
    "pca_counts = pca_rat_ctm.fit_transform(counts)\n",
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(pca_counts, classes, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_x, test_x, train_y, test_y = train_test_split(pca_counts, classes, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953125"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rat_pca_counts_logistic = LogisticRegression()\n",
    "#rat_pca_counts_logistic.fit(train_x, train_y)\n",
    "#accuracy_score(rat_pca_counts_logistic.predict(test_x), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9375, 0.890625, 0.90937500000000004)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neuron Dataset, 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_neuron_10topics = pickle.load(open(\"pickled_objects/model4all.p\", \"rb\"))\n",
    "classes_neuron_10topics = pickle.load(open(\"pickled_objects/ytrain4.p\", \"rb\"))\n",
    "vocab_neuron_10topics = pickle.load(open(\"pickled_objects/vocab4.p\", \"rb\"))\n",
    "counts_neuron_10topics = pickle.load(open(\"pickled_objects/xtrain4.p\", \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine classification accuracy using CTM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression using CTM Features\n",
      "Max Accuracy:  0.69 \n",
      "Min Accuracy:  0.51 \n",
      "Average Accuracy:  0.586\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy of Logistic Regression using CTM Features\"\n",
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(model_neuron_10topics.saved_lambdas, classes_neuron_10topics, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression using PCA Features with 10 principal components\n",
      "Max Accuracy:  0.94 \n",
      "Min Accuracy:  0.86 \n",
      "Average Accuracy:  0.898\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy of Logistic Regression using PCA Features with 10 principal components\"\n",
    "pca_neuron_10topics = PCA(n_components=10)\n",
    "pca_features_neuron_10topics = pca_neuron_10topics.fit_transform(counts_neuron_10topics)\n",
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(pca_features_neuron_10topics, classes_neuron_10topics, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression using original counts\n",
      "Max Accuracy:  0.96 \n",
      "Min Accuracy:  0.92 \n",
      "Average Accuracy:  0.936\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy of Logistic Regression using original counts\"\n",
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(counts_neuron_10topics, classes_neuron_10topics, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_x_neuron, test_x_neuron, train_y_neuron, test_y_neuron = train_test_split(model_neuron.saved_lambdas, classes_neuron, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train LogisticRegression classifier and make predictions\n",
    "# Accuracy Score is output\n",
    "#neuron_ctm_logistic = LogisticRegression()\n",
    "#neuron_ctm_logistic.fit(train_x_neuron, train_y_neuron)\n",
    "#accuracy_score(neuron_ctm_logistic.predict(test_x_neuron), test_y_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top genes in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: Slc25a4 Npy Dynll1 Snca Itm2b Rps29 Gstp1 Prnp Sub1 Syt1 Prkcb Tubb2a Hspa8 Hpca Syt11 Actg1 Atp5j2 Ywhaq Cox8a Camk2b Rplp1 Eef1a1 Gnas Stmn2\n",
      "\n",
      "Topic 2: Ptgds Cst3 Rps29 Actg1 Lars2 Scd2 Mog Dynll1 Syt11 Car2 Usmg5 Apod Cd81 Nrgn Enpp2 Serinc1 Itm2b Arl6ip1 Qk Atp5e Ftl1 Aldoa Tubb2a Cnp\n",
      "\n",
      "Topic 3: Rtn1 Snhg11 Ppp3ca Cpe Prkcb Serinc1 Scg5 Tubb2a Stmn3 Chn1 Tpi1 Olfm1 Nrgn Map1b Pja2 Cycs Rps29 Cox8a Eno2 Ndrg4 Calm3 Scn2a1 Atp6v1e1 Hspa8\n",
      "\n",
      "Topic 4: Gstp1 Mbp Apod Ptma Gpm6b Mog Scd2 Cd81 Ermn Cnp Dynll1 Cst3 Aplp1 Eef1a1 Enpp2 Itm2b Ptn Rtn3 Rpl32 H3f3b Syt11 Taldo1 Atp6v1a Atp5b\n",
      "\n",
      "Topic 5: Cpe Actg1 Slc25a4 Syt1 Mdh1 Ndufa4 Serinc1 Scg5 Ckb Sparcl1 Sub1 Prnp Tcf4 Atp6v0c-ps2 Rplp1 Atp5g3 Aldoa Slc1a2 Chn1 Usmg5 2900097C17Rik Cox7a2 Atp5j2 Ldhb\n",
      "\n",
      "Topic 6: Snhg11 Mdh1 Sub1 Scg5 Atp6v0c-ps2 Ttc3 Nrgn Actg1 Aldoa Tcf4 Serinc1 Ppp3ca 2900097C17Rik Eif4a2 Basp1 Ywhaz Tpi1 Olfm1 Tubb2a Atp5b Cox8a Atp5g3 Prnp Snca\n",
      "\n",
      "Topic 7: Ttr Enpp2 Cst3 Rtn1 Rps29 Snhg11 Syt11 Mdh1 Sub1 Cox7c Cox8a Apod Usmg5 Ugt8a Cpe Atp6v0c-ps2 Mog Ptgds Eif4a2 Lars2 Sep-07 Ckb Cd81 Mbp\n",
      "\n",
      "Topic 8: Cst3 Lars2 Ppp3ca Cpe Hspa8 Aldoa Tcf4 Chn1 Itm2b Map1b Ckb Cox7c Calm3 Atp6v1a Basp1 Eno2 Gdi1 Cox6b1 Dbi Fau Sparcl1 Mdh1 Snhg11 Sep-07\n",
      "\n",
      "Topic 9: Slc25a4 Stmn3 Ppp3ca Prkcb Chn1 Actg1 Pja2 Aldoa Syt1 Ndufa4 Gstp1 Cst3 Hspa8 Itm2b Cox6b1 Ywhaz Hpca Map1b Ttc3 Cpe Rps29 Olfm1 Cycs Cox6c\n",
      "\n",
      "Topic 10: Rtn1 Ttc3 Serinc1 Snca Aldoa Stmn3 Syt1 Ndufa4 Prkcb 2900097C17Rik Sparcl1 Stmn2 Eif4a2 Ywhaz Atp6v1a Ppp3ca Itm2b Cox8a Cpe Camk2n1 Sub1 Apoe Map1b Cox7c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the top genes in each topic\n",
    "n_top_words = 25\n",
    "for i, topic_dist in enumerate(model_neuron_10topics.beta):\n",
    "    topic_words = np.array(vocab_neuron_10topics)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i+1, ' '.join(topic_words)))\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6793648 , -0.020345  ,  0.03630703, -0.02157605,  0.02073142,\n",
       "         0.0333818 , -0.02719253,  0.0079505 ,  0.01641649,  0.02483679],\n",
       "       [-0.020345  ,  0.71648547, -0.06431401,  0.05732057, -0.03045045,\n",
       "        -0.05616994,  0.03658109, -0.00585334, -0.02133856, -0.03974921],\n",
       "       [ 0.03630703, -0.06431401,  0.77156903, -0.07241253,  0.05463224,\n",
       "         0.08810894, -0.06769471,  0.01858201,  0.03862574,  0.0683182 ],\n",
       "       [-0.02157605,  0.05732057, -0.07241253,  0.73071155, -0.03768986,\n",
       "        -0.05894758,  0.03950568, -0.00546624, -0.0230056 , -0.04379379],\n",
       "       [ 0.02073142, -0.03045045,  0.05463224, -0.03768986,  0.70034074,\n",
       "         0.04326739, -0.03548964,  0.01410758,  0.02109201,  0.03747016],\n",
       "       [ 0.0333818 , -0.05616994,  0.08810894, -0.05894758,  0.04326739,\n",
       "         0.74457972, -0.06022811,  0.0168485 ,  0.03590666,  0.05843572],\n",
       "       [-0.02719253,  0.03658109, -0.06769471,  0.03950568, -0.03548964,\n",
       "        -0.06022811,  0.70879195, -0.01580688, -0.03003908, -0.04651834],\n",
       "       [ 0.0079505 , -0.00585334,  0.01858201, -0.00546624,  0.01410758,\n",
       "         0.0168485 , -0.01580688,  0.67170368,  0.01081365,  0.01606861],\n",
       "       [ 0.01641649, -0.02133856,  0.03862574, -0.0230056 ,  0.02109201,\n",
       "         0.03590666, -0.03003908,  0.01081365,  0.68046194,  0.02738737],\n",
       "       [ 0.02483679, -0.03974921,  0.0683182 , -0.04379379,  0.03747016,\n",
       "         0.05843572, -0.04651834,  0.01606861,  0.02738737,  0.70972295]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_neuron_10topics.sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rat Dataset 30 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_rat_30topics = pickle.load(open(\"pickled_objects/modelrat30.p\", \"rb\"))\n",
    "classes_rat_30topics = pickle.load(open(\"pickled_objects/classesrat30.p\", \"rb\"))\n",
    "vocab_rat_30topics = pickle.load(open(\"pickled_objects/vocabrat30.p\", \"rb\"))\n",
    "counts_rat_30topics = pickle.load(open(\"pickled_objects/countsrat30.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine classification accuracy on CTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy:  1.0 \n",
      "Min Accuracy:  0.96875 \n",
      "Average Accuracy:  0.996875\n"
     ]
    }
   ],
   "source": [
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(model_rat_30topics.saved_lambdas, classes_rat_30topics, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine classification accuracy on PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression using PCA Features with 10 principal components\n",
      "Max Accuracy:  1.0 \n",
      "Min Accuracy:  0.96875 \n",
      "Average Accuracy:  0.984375\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy of Logistic Regression using PCA Features with 10 principal components\"\n",
    "pca_rat_30topics = PCA(n_components=30)\n",
    "pca_features_rat_30topics = pca_rat_30topics.fit_transform(counts_rat_30topics)\n",
    "min_acc, max_acc, avg_acc = KFoldCrossValidation(pca_features_rat_30topics, classes_rat_30topics, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Determine accuracy on LDA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
